{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2: Employee Attrition Prediction using Logistic Regression\n",
        "\n",
        "## Objective\n",
        "Employee attrition is a major concern for organisations as retaining skilled employees is crucial for business success. Predicting whether an employee will leave the company can help HR departments take proactive measures.\n",
        "\n",
        "In this notebook, we will:\n",
        "1. Load and explore the HR dataset\n",
        "2. Preprocess and prepare data for logistic regression\n",
        "3. Build a predictive model using logistic regression\n",
        "4. Analyze the coefficients and their significance\n",
        "5. Evaluate model performance\n",
        "6. Answer the assignment questions about coefficient interpretation\n",
        "\n",
        "### Target Variable:\n",
        "- **Attrition**: Yes = Left, No = Stayed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             confusion_matrix, classification_report, roc_curve, roc_auc_score)\n",
        "\n",
        "# Statistical analysis\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Settings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Load and Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the HR dataset\n",
        "df = pd.read_csv('../Task_2_Assets/hr_dataset.csv')\n",
        "\n",
        "# Display basic information\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nShape of dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "print(f\"\\nColumn names:\\n{df.columns.tolist()}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FIRST 5 ROWS\")\n",
        "print(\"=\"*60)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check data types and missing values\n",
        "print(\"DATA TYPES AND NON-NULL COUNTS\")\n",
        "print(\"=\"*60)\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MISSING VALUES\")\n",
        "print(\"=\"*60)\n",
        "missing = df.isnull().sum()\n",
        "print(missing[missing > 0] if missing.sum() > 0 else \"No missing values found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Target variable distribution\n",
        "print(\"TARGET VARIABLE: ATTRITION\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nValue Counts:\")\n",
        "print(df['Attrition'].value_counts())\n",
        "print(f\"\\nPercentage:\")\n",
        "print(df['Attrition'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Visualize target distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Count plot\n",
        "attrition_counts = df['Attrition'].value_counts()\n",
        "colors = ['#2ecc71', '#e74c3c']\n",
        "axes[0].bar(attrition_counts.index, attrition_counts.values, color=colors, edgecolor='black')\n",
        "axes[0].set_title('Attrition Distribution (Count)', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Attrition')\n",
        "axes[0].set_ylabel('Count')\n",
        "for i, v in enumerate(attrition_counts.values):\n",
        "    axes[0].text(i, v + 20, str(v), ha='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "# Pie chart\n",
        "axes[1].pie(attrition_counts.values, labels=attrition_counts.index, autopct='%1.1f%%', \n",
        "            colors=colors, explode=[0, 0.1], shadow=True, startangle=90)\n",
        "axes[1].set_title('Attrition Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze key features by Attrition\n",
        "key_features = ['Age', 'YearsAtCompany', 'MonthlyIncome', 'TotalWorkingYears', \n",
        "                'WorkLifeBalance', 'JobSatisfaction', 'EnvironmentSatisfaction']\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(key_features):\n",
        "    if feature in df.columns:\n",
        "        df.boxplot(column=feature, by='Attrition', ax=axes[i])\n",
        "        axes[i].set_title(f'{feature} by Attrition', fontsize=11, fontweight='bold')\n",
        "        axes[i].set_xlabel('Attrition')\n",
        "\n",
        "# Remove empty subplot\n",
        "axes[-1].axis('off')\n",
        "plt.suptitle('Key Features Distribution by Attrition Status', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze OverTime vs Attrition\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# OverTime distribution\n",
        "overtime_attrition = pd.crosstab(df['OverTime'], df['Attrition'])\n",
        "overtime_attrition.plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'], edgecolor='black')\n",
        "axes[0].set_title('OverTime vs Attrition', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('OverTime')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].legend(title='Attrition')\n",
        "axes[0].tick_params(axis='x', rotation=0)\n",
        "\n",
        "# Work-Life Balance vs Attrition\n",
        "wlb_attrition = pd.crosstab(df['WorkLifeBalance'], df['Attrition'])\n",
        "wlb_attrition.plot(kind='bar', ax=axes[1], color=['#2ecc71', '#e74c3c'], edgecolor='black')\n",
        "axes[1].set_title('Work-Life Balance vs Attrition', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('WorkLifeBalance (1=Low, 4=High)')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].legend(title='Attrition')\n",
        "axes[1].tick_params(axis='x', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print statistics\n",
        "print(\"\\nOverTime Attrition Rate:\")\n",
        "print((overtime_attrition['Yes'] / overtime_attrition.sum(axis=1) * 100).round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy for preprocessing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Convert target variable to binary (Yes=1, No=0)\n",
        "df_processed['Attrition'] = df_processed['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = df_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "numerical_cols.remove('Attrition')  # Remove target variable\n",
        "\n",
        "print(\"Categorical Columns:\", categorical_cols)\n",
        "print(\"\\nNumerical Columns:\", numerical_cols)\n",
        "\n",
        "# Remove columns that don't add value\n",
        "cols_to_drop = ['EmployeeCount', 'StandardHours', 'Over18', 'EmployeeNumber']\n",
        "cols_to_drop = [col for col in cols_to_drop if col in df_processed.columns]\n",
        "df_processed = df_processed.drop(columns=cols_to_drop)\n",
        "\n",
        "print(f\"\\nDropped columns: {cols_to_drop}\")\n",
        "print(f\"Remaining columns: {df_processed.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-hot encode categorical variables\n",
        "df_encoded = pd.get_dummies(df_processed, drop_first=True)\n",
        "\n",
        "print(\"Shape after encoding:\", df_encoded.shape)\n",
        "print(\"\\nEncoded columns sample:\")\n",
        "print(df_encoded.columns.tolist()[:20], \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target\n",
        "X = df_encoded.drop('Attrition', axis=1)\n",
        "y = df_encoded['Attrition']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
        "print(f\"\\nTarget distribution in training set:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame for feature names\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Building the Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = log_reg.predict(X_train_scaled)\n",
        "y_test_pred = log_reg.predict(X_test_scaled)\n",
        "y_test_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(\"Logistic Regression Model Training Complete!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze model coefficients\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': log_reg.coef_[0],\n",
        "    'Odds_Ratio': np.exp(log_reg.coef_[0])\n",
        "}).sort_values('Coefficient', ascending=False, key=abs)\n",
        "\n",
        "print(\"LOGISTIC REGRESSION COEFFICIENTS (Top 20 by magnitude)\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nIntercept:\", log_reg.intercept_[0])\n",
        "print(\"\\nTop 20 Features by Absolute Coefficient Value:\")\n",
        "print(coefficients.head(20).to_string(index=False))\n",
        "\n",
        "# Visualize top coefficients\n",
        "top_coefs = coefficients.head(15)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "colors = ['green' if c > 0 else 'red' for c in top_coefs['Coefficient']]\n",
        "bars = plt.barh(range(len(top_coefs)), top_coefs['Coefficient'], color=colors, edgecolor='black')\n",
        "plt.yticks(range(len(top_coefs)), top_coefs['Feature'])\n",
        "plt.axvline(x=0, color='black', linewidth=0.8)\n",
        "plt.xlabel('Coefficient Value', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Top 15 Logistic Regression Coefficients\\n(Positive = Higher Attrition Risk)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Evaluation Metrics\n",
        "print(\"MODEL EVALUATION METRICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n--- Training Set ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "\n",
        "print(\"\\n--- Testing Set ---\")\n",
        "print(f\"Accuracy:  {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"F1 Score:  {f1_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"ROC AUC:   {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
        "\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['No Attrition', 'Attrition']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix and ROC Curve\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=['No Attrition', 'Attrition'],\n",
        "            yticklabels=['No Attrition', 'Attrition'])\n",
        "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
        "auc = roc_auc_score(y_test, y_test_proba)\n",
        "axes[1].plot(fpr, tpr, color='blue', linewidth=2, label=f'ROC Curve (AUC = {auc:.3f})')\n",
        "axes[1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
        "axes[1].fill_between(fpr, tpr, alpha=0.2)\n",
        "axes[1].set_xlabel('False Positive Rate', fontsize=11)\n",
        "axes[1].set_ylabel('True Positive Rate', fontsize=11)\n",
        "axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
        "axes[1].legend(loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Answers to Assignment Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1: Coefficient Interpretation and Strongest Influence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze coefficients for Question 1\n",
        "print(\"=\"*80)\n",
        "print(\"QUESTION 1: Coefficient Interpretation and Feature Influence\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Sort by coefficient value\n",
        "positive_coefs = coefficients[coefficients['Coefficient'] > 0].sort_values('Coefficient', ascending=False).head(10)\n",
        "negative_coefs = coefficients[coefficients['Coefficient'] < 0].sort_values('Coefficient', ascending=True).head(10)\n",
        "\n",
        "print(\"\\n1. POSITIVE COEFFICIENTS (Increase Attrition Risk):\")\n",
        "print(\"-\"*60)\n",
        "for _, row in positive_coefs.iterrows():\n",
        "    print(f\"   {row['Feature']:35s}: +{row['Coefficient']:.4f} (Odds Ratio: {row['Odds_Ratio']:.4f})\")\n",
        "\n",
        "print(\"\\n2. NEGATIVE COEFFICIENTS (Decrease Attrition Risk):\")\n",
        "print(\"-\"*60)\n",
        "for _, row in negative_coefs.iterrows():\n",
        "    print(f\"   {row['Feature']:35s}: {row['Coefficient']:.4f} (Odds Ratio: {row['Odds_Ratio']:.4f})\")\n",
        "\n",
        "# Find strongest influence\n",
        "strongest = coefficients.iloc[0]\n",
        "print(f\"\\n3. STRONGEST INFLUENCE ON ATTRITION:\")\n",
        "print(\"-\"*60)\n",
        "print(f\"   Feature: {strongest['Feature']}\")\n",
        "print(f\"   Coefficient: {strongest['Coefficient']:.4f}\")\n",
        "print(f\"   Odds Ratio: {strongest['Odds_Ratio']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Answer to Question 1: Coefficient Interpretation\n",
        "\n",
        "In logistic regression, coefficients indicate the direction and magnitude of the relationship between each independent variable and the log-odds of the target variable (Attrition).\n",
        "\n",
        "**Interpretation of Coefficients:**\n",
        "\n",
        "1. **Positive Coefficient**: A positive coefficient means that as the feature value increases, the **probability of attrition increases**. For example, if OverTime has a positive coefficient, employees who work overtime are more likely to leave.\n",
        "\n",
        "2. **Negative Coefficient**: A negative coefficient means that as the feature value increases, the **probability of attrition decreases**. For example, if YearsAtCompany has a negative coefficient, employees with longer tenure are less likely to leave.\n",
        "\n",
        "3. **Odds Ratio**: The exponentiated coefficient (e^Î²) gives the odds ratio, which tells us how much the odds of attrition multiply for each one-unit increase in the feature. An odds ratio > 1 increases attrition risk, while an odds ratio < 1 decreases it.\n",
        "\n",
        "**Key Findings:**\n",
        "- Features with high positive coefficients (like OverTime, JobLevel in certain roles) increase attrition risk\n",
        "- Features with negative coefficients (like YearsAtCompany, JobInvolvement) decrease attrition risk\n",
        "- The feature with the largest absolute coefficient has the **strongest influence** on employee attrition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2: Practical Implications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze specific features for Question 2\n",
        "print(\"=\"*80)\n",
        "print(\"QUESTION 2: Practical Implications Analysis\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get coefficients for key features mentioned in the question\n",
        "key_features_q2 = ['OverTime_Yes', 'WorkLifeBalance', 'MonthlyIncome', 'YearsAtCompany']\n",
        "\n",
        "print(\"\\nKey Features Analysis:\")\n",
        "print(\"-\"*60)\n",
        "for feature in key_features_q2:\n",
        "    if feature in coefficients['Feature'].values:\n",
        "        row = coefficients[coefficients['Feature'] == feature].iloc[0]\n",
        "        print(f\"\\n{feature}:\")\n",
        "        print(f\"   Coefficient: {row['Coefficient']:.4f}\")\n",
        "        print(f\"   Odds Ratio: {row['Odds_Ratio']:.4f}\")\n",
        "        if row['Coefficient'] > 0:\n",
        "            print(f\"   Interpretation: INCREASES attrition risk\")\n",
        "        else:\n",
        "            print(f\"   Interpretation: DECREASES attrition risk\")\n",
        "    else:\n",
        "        # Check for similar features\n",
        "        similar = coefficients[coefficients['Feature'].str.contains(feature.split('_')[0], case=False)]\n",
        "        if len(similar) > 0:\n",
        "            print(f\"\\n{feature} (related features):\")\n",
        "            for _, r in similar.head(3).iterrows():\n",
        "                print(f\"   {r['Feature']}: {r['Coefficient']:.4f} (OR: {r['Odds_Ratio']:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Answer to Question 2: Practical Implications\n",
        "\n",
        "**1. If Work-Life Balance has a Negative Coefficient:**\n",
        "\n",
        "A negative coefficient for Work-Life Balance implies that as work-life balance **improves** (higher scores), the probability of attrition **decreases**. This makes intuitive sense because:\n",
        "\n",
        "- Employees with better work-life balance are more satisfied with their jobs\n",
        "- They experience less burnout and stress\n",
        "- They have time for personal pursuits, family, and self-care\n",
        "- They feel the organization values their well-being\n",
        "\n",
        "**HR Implication**: Organizations should invest in work-life balance initiatives such as flexible working hours, remote work options, and reasonable workloads to reduce attrition.\n",
        "\n",
        "---\n",
        "\n",
        "**2. If OverTime has a High Positive Coefficient:**\n",
        "\n",
        "A high positive coefficient for OverTime suggests that employees who frequently work overtime are **significantly more likely** to leave. This indicates:\n",
        "\n",
        "- Overtime work leads to burnout and dissatisfaction\n",
        "- Employees feel overworked and undervalued\n",
        "- Work-life balance suffers when overtime is frequent\n",
        "- It may signal poor resource planning or unrealistic workloads\n",
        "\n",
        "**HR Implication**: Management should monitor overtime patterns, hire additional staff if needed, improve project planning, and ensure overtime is compensated fairly. Persistent overtime is a strong warning sign for potential attrition.\n",
        "\n",
        "---\n",
        "\n",
        "**3. If Salary/Monthly Income has a Small or Non-Significant Coefficient:**\n",
        "\n",
        "A small or non-significant coefficient for Salary Level suggests that salary alone may not be a primary driver of attrition. This could be because:\n",
        "\n",
        "- **Base salaries are competitive**: If the organization already pays market-competitive salaries, further increases have diminishing returns\n",
        "- **Other factors matter more**: Work environment, growth opportunities, management quality, and work-life balance may be more important than salary\n",
        "- **Threshold effect**: Once employees earn above a certain threshold, additional income has less impact on their decision to stay\n",
        "- **Non-monetary compensation**: Benefits, recognition, career development opportunities may compensate for salary concerns\n",
        "\n",
        "**HR Implication**: While competitive salaries are important, organizations should not rely solely on compensation to retain employees. Focus on holistic employee experience including career development, work environment, and meaningful work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Summary and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Summary\n",
        "print(\"=\"*80)\n",
        "print(\"FINAL SUMMARY: EMPLOYEE ATTRITION PREDICTION MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. MODEL PERFORMANCE:\")\n",
        "print(\"-\"*60)\n",
        "print(f\"   - Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"   - ROC AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
        "print(f\"   - Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"   - Recall: {recall_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "print(\"\\n2. TOP FACTORS INCREASING ATTRITION RISK:\")\n",
        "print(\"-\"*60)\n",
        "for i, (_, row) in enumerate(positive_coefs.head(5).iterrows(), 1):\n",
        "    print(f\"   {i}. {row['Feature']}: +{row['Coefficient']:.4f}\")\n",
        "\n",
        "print(\"\\n3. TOP FACTORS DECREASING ATTRITION RISK:\")\n",
        "print(\"-\"*60)\n",
        "for i, (_, row) in enumerate(negative_coefs.head(5).iterrows(), 1):\n",
        "    print(f\"   {i}. {row['Feature']}: {row['Coefficient']:.4f}\")\n",
        "\n",
        "print(\"\\n4. KEY HR RECOMMENDATIONS:\")\n",
        "print(\"-\"*60)\n",
        "print(\"   - Monitor and reduce overtime requirements\")\n",
        "print(\"   - Improve work-life balance initiatives\")\n",
        "print(\"   - Focus on employee engagement and job satisfaction\")\n",
        "print(\"   - Invest in career development and growth opportunities\")\n",
        "print(\"   - Address environmental and relationship satisfaction factors\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"END OF TASK 2 SOLUTION\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
