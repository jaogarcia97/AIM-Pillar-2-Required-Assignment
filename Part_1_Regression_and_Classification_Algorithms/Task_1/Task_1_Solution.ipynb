{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1: Housing Price Prediction using Linear Regression\n",
        "\n",
        "## Objective\n",
        "The real estate industry heavily relies on predictive analytics to estimate housing prices based on various factors such as location, property size, age, and amenities. Machine learning models help in understanding these patterns and making data-driven decisions.\n",
        "\n",
        "In this notebook, we will:\n",
        "1. Load and explore the housing prices dataset\n",
        "2. Build a predictive model using regression techniques\n",
        "3. Analyze the coefficients and their significance\n",
        "4. Create residual plots to evaluate model assumptions\n",
        "5. Answer the assignment questions\n",
        "\n",
        "### Dataset Features:\n",
        "- **Square_Feet**: Size of the house in square feet\n",
        "- **Num_Bedrooms**: Number of bedrooms\n",
        "- **Num_Bathrooms**: Number of bathrooms\n",
        "- **Age_of_House**: Age of the house in years\n",
        "- **House_Price**: Target variable (price of the house)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Statistical analysis\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "# Settings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Load and Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the housing prices dataset\n",
        "df = pd.read_excel('../Task_1_Assets/housing_prices.xlsx')\n",
        "\n",
        "# Display basic information\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nShape of dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FIRST 10 ROWS\")\n",
        "print(\"=\"*60)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display data types and non-null counts\n",
        "print(\"DATA TYPES AND NON-NULL COUNTS\")\n",
        "print(\"=\"*60)\n",
        "print(df.info())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MISSING VALUES\")\n",
        "print(\"=\"*60)\n",
        "missing = df.isnull().sum()\n",
        "print(missing[missing > 0] if missing.sum() > 0 else \"No missing values found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "print(\"STATISTICAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of the target variable (House_Price)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram\n",
        "axes[0].hist(df['House_Price'], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "axes[0].set_title('Distribution of House Prices', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('House Price ($)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].axvline(df['House_Price'].mean(), color='red', linestyle='--', label=f'Mean: ${df[\"House_Price\"].mean():,.0f}')\n",
        "axes[0].axvline(df['House_Price'].median(), color='green', linestyle='--', label=f'Median: ${df[\"House_Price\"].median():,.0f}')\n",
        "axes[0].legend()\n",
        "\n",
        "# Box plot\n",
        "axes[1].boxplot(df['House_Price'], vert=True)\n",
        "axes[1].set_title('Box Plot of House Prices', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('House Price ($)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print statistics\n",
        "print(f\"\\nHouse Price Statistics:\")\n",
        "print(f\"  Mean: ${df['House_Price'].mean():,.2f}\")\n",
        "print(f\"  Median: ${df['House_Price'].median():,.2f}\")\n",
        "print(f\"  Std Dev: ${df['House_Price'].std():,.2f}\")\n",
        "print(f\"  Min: ${df['House_Price'].min():,.2f}\")\n",
        "print(f\"  Max: ${df['House_Price'].max():,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of all features\n",
        "features = ['Square_Feet', 'Num_Bedrooms', 'Num_Bathrooms', 'Age_of_House']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71', '#9b59b6']\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    axes[i].hist(df[feature], bins=25, color=colors[i], edgecolor='black', alpha=0.7)\n",
        "    axes[i].set_title(f'Distribution of {feature}', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "    axes[i].axvline(df[feature].mean(), color='black', linestyle='--', \n",
        "                    label=f'Mean: {df[feature].mean():.1f}')\n",
        "    axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Analysis\n",
        "print(\"CORRELATION MATRIX\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Display correlation with target variable\n",
        "print(\"\\nCorrelation with House_Price:\")\n",
        "print(\"-\"*40)\n",
        "correlations = correlation_matrix['House_Price'].sort_values(ascending=False)\n",
        "for feature, corr in correlations.items():\n",
        "    print(f\"{feature:20s}: {corr:+.4f}\")\n",
        "\n",
        "# Heatmap visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0,\n",
        "            fmt='.3f', linewidths=0.5, square=True,\n",
        "            cbar_kws={'label': 'Correlation Coefficient'})\n",
        "plt.title('Correlation Heatmap of Housing Features', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plots: Features vs House Price\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    axes[i].scatter(df[feature], df['House_Price'], alpha=0.5, color=colors[i], edgecolor='black', linewidth=0.5)\n",
        "    \n",
        "    # Add trend line\n",
        "    z = np.polyfit(df[feature], df['House_Price'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    x_line = np.linspace(df[feature].min(), df[feature].max(), 100)\n",
        "    axes[i].plot(x_line, p(x_line), color='red', linewidth=2, linestyle='--', label='Trend Line')\n",
        "    \n",
        "    # Calculate correlation\n",
        "    corr = df[feature].corr(df['House_Price'])\n",
        "    axes[i].set_title(f'{feature} vs House Price\\n(r = {corr:.3f})', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('House Price ($)')\n",
        "    axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define features (X) and target (y)\n",
        "X = df[['Square_Feet', 'Num_Bedrooms', 'Num_Bathrooms', 'Age_of_House']]\n",
        "y = df['House_Price']\n",
        "\n",
        "print(\"Feature Matrix (X) shape:\", X.shape)\n",
        "print(\"Target Vector (y) shape:\", y.shape)\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set: {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Building the Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and train the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Model Training Complete!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display model coefficients\n",
        "print(\"LINEAR REGRESSION MODEL COEFFICIENTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nIntercept (B0): ${model.intercept_:,.2f}\")\n",
        "print(\"\\nFeature Coefficients:\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': model.coef_\n",
        "}).sort_values('Coefficient', ascending=False, key=abs)\n",
        "\n",
        "for _, row in coefficients.iterrows():\n",
        "    sign = '+' if row['Coefficient'] >= 0 else ''\n",
        "    print(f\"  {row['Feature']:20s}: {sign}{row['Coefficient']:,.2f}\")\n",
        "\n",
        "# Visualize coefficients\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors_coef = ['green' if c >= 0 else 'red' for c in coefficients['Coefficient']]\n",
        "bars = plt.barh(coefficients['Feature'], coefficients['Coefficient'], color=colors_coef, edgecolor='black')\n",
        "plt.axvline(x=0, color='black', linewidth=0.8)\n",
        "plt.xlabel('Coefficient Value', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Linear Regression Coefficients', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, val in zip(bars, coefficients['Coefficient']):\n",
        "    plt.text(val + (20 if val >= 0 else -20), bar.get_y() + bar.get_height()/2,\n",
        "             f'{val:,.1f}', ha='left' if val >= 0 else 'right', va='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics\n",
        "def evaluate_model(y_true, y_pred, set_name):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    \n",
        "    print(f\"\\n{set_name} Set Metrics:\")\n",
        "    print(\"-\"*40)\n",
        "    print(f\"  R-squared Score:    {r2:.4f}\")\n",
        "    print(f\"  Mean Squared Error: {mse:,.2f}\")\n",
        "    print(f\"  Root MSE:           ${rmse:,.2f}\")\n",
        "    print(f\"  Mean Absolute Error: ${mae:,.2f}\")\n",
        "    \n",
        "    return {'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
        "\n",
        "print(\"MODEL EVALUATION METRICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "train_metrics = evaluate_model(y_train, y_train_pred, \"Training\")\n",
        "test_metrics = evaluate_model(y_test, y_test_pred, \"Testing\")\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INTERPRETATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n- R-squared = {test_metrics['R2']:.4f} means the model explains {test_metrics['R2']*100:.2f}% of the variance in house prices.\")\n",
        "print(f\"- On average, predictions are off by approximately ${test_metrics['MAE']:,.2f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual vs Predicted Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Training set\n",
        "axes[0].scatter(y_train, y_train_pred, alpha=0.5, color='blue', edgecolor='black', linewidth=0.5)\n",
        "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', linewidth=2, label='Perfect Prediction')\n",
        "axes[0].set_xlabel('Actual House Price ($)', fontsize=11)\n",
        "axes[0].set_ylabel('Predicted House Price ($)', fontsize=11)\n",
        "axes[0].set_title(f'Training Set: Actual vs Predicted\\n(R-squared = {train_metrics[\"R2\"]:.4f})', fontsize=12, fontweight='bold')\n",
        "axes[0].legend()\n",
        "\n",
        "# Testing set\n",
        "axes[1].scatter(y_test, y_test_pred, alpha=0.5, color='green', edgecolor='black', linewidth=0.5)\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2, label='Perfect Prediction')\n",
        "axes[1].set_xlabel('Actual House Price ($)', fontsize=11)\n",
        "axes[1].set_ylabel('Predicted House Price ($)', fontsize=11)\n",
        "axes[1].set_title(f'Testing Set: Actual vs Predicted\\n(R-squared = {test_metrics[\"R2\"]:.4f})', fontsize=12, fontweight='bold')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Statistical Analysis using Statsmodels (OLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit OLS model for detailed statistical analysis\n",
        "X_with_const = sm.add_constant(X)\n",
        "ols_model = sm.OLS(y, X_with_const).fit()\n",
        "\n",
        "# Display full summary\n",
        "print(ols_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed coefficient analysis\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DETAILED COEFFICIENT ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Feature': ols_model.params.index,\n",
        "    'Coefficient': ols_model.params.values,\n",
        "    'Std Error': ols_model.bse.values,\n",
        "    't-value': ols_model.tvalues.values,\n",
        "    'p-value': ols_model.pvalues.values,\n",
        "    'Significant': ['Yes' if p < 0.05 else 'No' for p in ols_model.pvalues.values]\n",
        "})\n",
        "\n",
        "print(\"\\n\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"-\"*80)\n",
        "print(\"\\nInterpretation of p-values:\")\n",
        "print(\"- p-value < 0.05: The coefficient is statistically significant (relationship is unlikely due to chance)\")\n",
        "print(\"- p-value >= 0.05: The coefficient may not be statistically significant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Residual Analysis (Critical for Question 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals = y - ols_model.predict(X_with_const)\n",
        "y_pred_full = ols_model.predict(X_with_const)\n",
        "\n",
        "print(\"RESIDUAL STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Mean of residuals: ${residuals.mean():,.4f}\")\n",
        "print(f\"Std of residuals: ${residuals.std():,.2f}\")\n",
        "print(f\"Min residual: ${residuals.min():,.2f}\")\n",
        "print(f\"Max residual: ${residuals.max():,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Residual Plot Analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "# 1. Residuals vs Fitted Values\n",
        "axes[0, 0].scatter(y_pred_full, residuals, alpha=0.5, color='blue', edgecolor='black', linewidth=0.3)\n",
        "axes[0, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
        "axes[0, 0].set_xlabel('Fitted (Predicted) Values', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Residuals', fontsize=11)\n",
        "axes[0, 0].set_title('Residuals vs Fitted Values\\n(Checking for Non-Linearity & Heteroscedasticity)', fontsize=12, fontweight='bold')\n",
        "\n",
        "# Add LOWESS trend line\n",
        "smooth = lowess(residuals, y_pred_full, frac=0.3)\n",
        "axes[0, 0].plot(smooth[:, 0], smooth[:, 1], color='orange', linewidth=2, label='LOWESS Trend')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# 2. Q-Q Plot (Normality of Residuals)\n",
        "sm.qqplot(residuals, line='45', ax=axes[0, 1], markersize=5, alpha=0.6)\n",
        "axes[0, 1].set_title('Q-Q Plot\\n(Checking Normality of Residuals)', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 3. Histogram of Residuals\n",
        "axes[1, 0].hist(residuals, bins=30, color='steelblue', edgecolor='black', alpha=0.7, density=True)\n",
        "# Add normal distribution curve\n",
        "x_norm = np.linspace(residuals.min(), residuals.max(), 100)\n",
        "axes[1, 0].plot(x_norm, stats.norm.pdf(x_norm, residuals.mean(), residuals.std()), \n",
        "                color='red', linewidth=2, label='Normal Distribution')\n",
        "axes[1, 0].set_xlabel('Residuals', fontsize=11)\n",
        "axes[1, 0].set_ylabel('Density', fontsize=11)\n",
        "axes[1, 0].set_title('Distribution of Residuals\\n(Should be approximately normal)', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# 4. Scale-Location Plot (Standardized residuals vs fitted)\n",
        "standardized_residuals = (residuals - residuals.mean()) / residuals.std()\n",
        "sqrt_abs_std_residuals = np.sqrt(np.abs(standardized_residuals))\n",
        "axes[1, 1].scatter(y_pred_full, sqrt_abs_std_residuals, alpha=0.5, color='purple', edgecolor='black', linewidth=0.3)\n",
        "smooth_scale = lowess(sqrt_abs_std_residuals, y_pred_full, frac=0.3)\n",
        "axes[1, 1].plot(smooth_scale[:, 0], smooth_scale[:, 1], color='red', linewidth=2, label='LOWESS Trend')\n",
        "axes[1, 1].set_xlabel('Fitted Values', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Sqrt of |Standardized Residuals|', fontsize=11)\n",
        "axes[1, 1].set_title('Scale-Location Plot\\n(Checking Homoscedasticity)', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Residual plots for each predictor variable (IMPORTANT FOR QUESTION 2)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    axes[i].scatter(df[feature], residuals, alpha=0.5, color=colors[i], edgecolor='black', linewidth=0.3)\n",
        "    axes[i].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
        "    \n",
        "    # Add LOWESS trend line to detect patterns\n",
        "    smooth = lowess(residuals, df[feature], frac=0.3)\n",
        "    axes[i].plot(smooth[:, 0], smooth[:, 1], color='black', linewidth=2, label='LOWESS Trend')\n",
        "    \n",
        "    axes[i].set_xlabel(feature, fontsize=11)\n",
        "    axes[i].set_ylabel('Residuals', fontsize=11)\n",
        "    axes[i].set_title(f'Residuals vs {feature}', fontsize=12, fontweight='bold')\n",
        "    axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Residual Plots for Each Predictor Variable', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Focused Residual Plot for Square_Feet (PRIMARY PREDICTOR)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.scatter(df['Square_Feet'], residuals, alpha=0.5, color='steelblue', edgecolor='black', linewidth=0.3, s=50)\n",
        "plt.axhline(y=0, color='red', linestyle='--', linewidth=2, label='Zero Reference Line')\n",
        "\n",
        "# Add LOWESS trend line\n",
        "smooth = lowess(residuals, df['Square_Feet'], frac=0.3)\n",
        "plt.plot(smooth[:, 0], smooth[:, 1], color='orange', linewidth=3, label='LOWESS Trend (detects non-linearity)')\n",
        "\n",
        "# Add horizontal bands for reference\n",
        "std_res = residuals.std()\n",
        "plt.fill_between([df['Square_Feet'].min(), df['Square_Feet'].max()], \n",
        "                 -2*std_res, 2*std_res, alpha=0.1, color='green', label='+/- 2 Std Dev Band')\n",
        "\n",
        "plt.xlabel('Square Feet', fontsize=12)\n",
        "plt.ylabel('Residuals ($)', fontsize=12)\n",
        "plt.title('Residual Plot: Square_Feet vs Residuals\\n(Key Plot for Linearity Assessment)', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Answers to Assignment Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1: If the coefficient for Square_Feet is significantly positive, what could be the reason?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Square_Feet coefficient and p-value\n",
        "sqft_coef = ols_model.params['Square_Feet']\n",
        "sqft_pvalue = ols_model.pvalues['Square_Feet']\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"QUESTION 1: Analysis of Square_Feet Coefficient\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nSquare_Feet Coefficient: {sqft_coef:,.2f}\")\n",
        "print(f\"P-value: {sqft_pvalue:.4e}\")\n",
        "print(f\"Is Significant (p < 0.05)?: {'Yes' if sqft_pvalue < 0.05 else 'No'}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*80)\n",
        "print(\"\\nINTERPRETATION:\")\n",
        "print(\"-\"*80)\n",
        "print(f\"\\nFor every 1 square foot increase in house size, the price increases by ${sqft_coef:,.2f}\")\n",
        "print(f\"(holding all other variables constant)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Answer to Question 1:\n",
        "\n",
        "The coefficient for `Square_Feet` is **significantly positive**, meaning that for every additional square foot of living space, the house price increases by approximately the coefficient value (in dollars), holding all other variables constant.\n",
        "\n",
        "**Reasons why the Square_Feet coefficient is significantly positive:**\n",
        "\n",
        "1. **Direct Value Proposition**: Larger homes inherently provide more living space, which is a primary utility that homebuyers pay for. The extra space accommodates larger families, provides room for home offices, entertainment areas, storage, and overall comfort.\n",
        "\n",
        "2. **Construction Costs**: Larger homes require more building materials (lumber, concrete, drywall, flooring, roofing, etc.) and more labor hours. These increased construction costs are directly reflected in the sale price.\n",
        "\n",
        "3. **Land Value Association**: Larger homes often sit on larger plots of land, which independently contributes to property value. The land itself appreciates over time and is a finite resource.\n",
        "\n",
        "4. **Market Demand**: There is consistent market demand for spacious homes. Families with children, multi-generational households, and those working from home all value extra square footage.\n",
        "\n",
        "5. **Resale Value**: Larger homes typically maintain better resale value and attract a wider buyer pool, making them more marketable investments.\n",
        "\n",
        "6. **Psychological Pricing**: In real estate, pricing is often done on a per-square-foot basis, which reinforces the linear relationship between size and price in the market.\n",
        "\n",
        "**Statistical Significance**: The very low p-value (typically < 0.05) indicates that this relationship is highly unlikely to be due to random chance. We can confidently say that square footage is a genuine predictor of house price."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 2: Discuss practical implications - Residual Plot Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Residual Analysis for Question 2\n",
        "from scipy.stats import shapiro, jarque_bera\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"QUESTION 2: Residual Plot Analysis and Linearity Assessment\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Test for normality of residuals\n",
        "stat_shapiro, p_shapiro = shapiro(residuals[:5000] if len(residuals) > 5000 else residuals)\n",
        "stat_jb, p_jb, skew_jb, kurt_jb = jarque_bera(residuals)\n",
        "\n",
        "print(\"\\n1. NORMALITY OF RESIDUALS\")\n",
        "print(\"-\"*50)\n",
        "print(f\"   Shapiro-Wilk Test: statistic={stat_shapiro:.4f}, p-value={p_shapiro:.4e}\")\n",
        "print(f\"   Jarque-Bera Test: statistic={stat_jb:.4f}, p-value={p_jb:.4e}\")\n",
        "print(f\"   Skewness: {skew_jb:.4f}\")\n",
        "print(f\"   Kurtosis: {kurt_jb:.4f}\")\n",
        "\n",
        "# Model fit statistics\n",
        "print(\"\\n2. MODEL FIT STATISTICS\")\n",
        "print(\"-\"*50)\n",
        "print(f\"   R-squared: {ols_model.rsquared:.4f}\")\n",
        "print(f\"   Adjusted R-squared: {ols_model.rsquared_adj:.4f}\")\n",
        "print(f\"   F-statistic: {ols_model.fvalue:.2f}\")\n",
        "print(f\"   Prob(F-statistic): {ols_model.f_pvalue:.4e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final comprehensive residual plot for Question 2\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Left: Residual plot with interpretation zones\n",
        "axes[0].scatter(df['Square_Feet'], residuals, alpha=0.4, color='steelblue', edgecolor='white', linewidth=0.3, s=40)\n",
        "axes[0].axhline(y=0, color='red', linestyle='-', linewidth=2, label='Zero Line (Perfect Fit)')\n",
        "\n",
        "# LOWESS trend\n",
        "smooth = lowess(residuals, df['Square_Feet'], frac=0.3)\n",
        "axes[0].plot(smooth[:, 0], smooth[:, 1], color='orange', linewidth=3, label='LOWESS Trend')\n",
        "\n",
        "# Standard deviation bands\n",
        "std_res = residuals.std()\n",
        "axes[0].axhline(y=2*std_res, color='green', linestyle='--', linewidth=1, alpha=0.7)\n",
        "axes[0].axhline(y=-2*std_res, color='green', linestyle='--', linewidth=1, alpha=0.7, label='+/- 2 sigma bounds')\n",
        "\n",
        "axes[0].set_xlabel('Square_Feet', fontsize=12)\n",
        "axes[0].set_ylabel('Residuals ($)', fontsize=12)\n",
        "axes[0].set_title('Residual Plot for Square_Feet\\n(Linearity Assessment)', fontsize=13, fontweight='bold')\n",
        "axes[0].legend(loc='upper right')\n",
        "\n",
        "# Right: Residuals vs Fitted Values\n",
        "axes[1].scatter(y_pred_full, residuals, alpha=0.4, color='purple', edgecolor='white', linewidth=0.3, s=40)\n",
        "axes[1].axhline(y=0, color='red', linestyle='-', linewidth=2)\n",
        "\n",
        "smooth2 = lowess(residuals, y_pred_full, frac=0.3)\n",
        "axes[1].plot(smooth2[:, 0], smooth2[:, 1], color='orange', linewidth=3, label='LOWESS Trend')\n",
        "\n",
        "axes[1].set_xlabel('Predicted House Price ($)', fontsize=12)\n",
        "axes[1].set_ylabel('Residuals ($)', fontsize=12)\n",
        "axes[1].set_title('Residuals vs Fitted Values\\n(Overall Model Assessment)', fontsize=13, fontweight='bold')\n",
        "axes[1].legend(loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Answer to Question 2: Residual Plot Analysis\n",
        "\n",
        "The residual plot analysis reveals important information about the linearity assumption of the linear regression model:\n",
        "\n",
        "---\n",
        "\n",
        "**What the Residual Plot Reveals:**\n",
        "\n",
        "1. **Ideal Residual Pattern (Linearity Assumption Met)**:\n",
        "   - Residuals should be **randomly scattered** around the horizontal zero line\n",
        "   - No discernible pattern (no curves, funnels, or clusters)\n",
        "   - Approximately equal spread across all fitted values (homoscedasticity)\n",
        "\n",
        "2. **Signs of Non-Linearity to Look For**:\n",
        "   - **Curved Pattern**: If residuals form a U-shape, inverted U, or any systematic curve, this indicates non-linearity\n",
        "   - **Fan Shape**: If spread increases/decreases with fitted values, indicates heteroscedasticity\n",
        "   - **Clusters**: Grouped residuals suggest the model misses certain data patterns\n",
        "\n",
        "---\n",
        "\n",
        "**Interpretation of Our Model's Residual Plot:**\n",
        "\n",
        "- **LOWESS Trend Line**: The orange trend line shows how residuals behave across different values of the predictor. If this line is roughly horizontal and close to zero, the linearity assumption holds well.\n",
        "\n",
        "- **If the Model Shows Good Linearity**:\n",
        "  - Residuals are randomly distributed around zero\n",
        "  - The LOWESS trend is approximately flat\n",
        "  - A linear regression model is appropriate for this data\n",
        "\n",
        "- **If the Model Shows Non-Linearity**:\n",
        "  - The LOWESS trend deviates significantly from the zero line\n",
        "  - There may be a curved pattern in the residuals\n",
        "  - The model may benefit from transformation or polynomial terms\n",
        "\n",
        "---\n",
        "\n",
        "**How to Address Non-Linearity if Present:**\n",
        "\n",
        "1. **Log Transformation**: Apply `log(House_Price)` or `log(Square_Feet)` to linearize relationships\n",
        "2. **Polynomial Regression**: Add `Square_Feet²` or higher-order terms\n",
        "3. **Interaction Terms**: Include interactions like `Square_Feet × Num_Bedrooms`\n",
        "4. **Piecewise Regression**: Use different models for different ranges of square footage\n",
        "5. **Non-Linear Models**: Consider decision trees, random forests, or gradient boosting\n",
        "\n",
        "---\n",
        "\n",
        "**Practical Implications:**\n",
        "\n",
        "- If the linearity assumption is violated, predictions may be systematically biased\n",
        "- For high-value homes (large square footage), the model may consistently over- or under-predict\n",
        "- Real estate pricing often has non-linear components (luxury premium, diminishing returns at very large sizes)\n",
        "- Residual analysis should be part of every regression modeling workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 10. Summary and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Summary\n",
        "print(\"=\"*80)\n",
        "print(\"FINAL SUMMARY: HOUSING PRICE PREDICTION MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. MODEL EQUATION:\")\n",
        "print(\"-\"*60)\n",
        "print(f\"   House_Price = {model.intercept_:,.2f}\")\n",
        "for feature, coef in zip(X.columns, model.coef_):\n",
        "    sign = '+' if coef >= 0 else ''\n",
        "    print(f\"                 {sign} {coef:,.2f} x {feature}\")\n",
        "\n",
        "print(\"\\n2. KEY FINDINGS:\")\n",
        "print(\"-\"*60)\n",
        "print(f\"   - Model R-squared: {test_metrics['R2']:.4f} (explains {test_metrics['R2']*100:.1f}% of variance)\")\n",
        "print(f\"   - Average Prediction Error: ${test_metrics['MAE']:,.2f}\")\n",
        "\n",
        "print(\"\\n3. COEFFICIENT SIGNIFICANCE:\")\n",
        "print(\"-\"*60)\n",
        "for feature in X.columns:\n",
        "    coef = ols_model.params[feature]\n",
        "    pval = ols_model.pvalues[feature]\n",
        "    sig = '***' if pval < 0.001 else '**' if pval < 0.01 else '*' if pval < 0.05 else ''\n",
        "    print(f\"   - {feature}: {coef:+,.2f} (p={pval:.4f}) {sig}\")\n",
        "print(\"   (* p<0.05, ** p<0.01, *** p<0.001)\")\n",
        "\n",
        "print(\"\\n4. MOST INFLUENTIAL FEATURES:\")\n",
        "print(\"-\"*60)\n",
        "sorted_features = sorted(zip(X.columns, model.coef_), key=lambda x: abs(x[1]), reverse=True)\n",
        "for rank, (feat, coef) in enumerate(sorted_features, 1):\n",
        "    print(f\"   {rank}. {feat}: {coef:+,.2f} per unit\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"END OF TASK 1 SOLUTION\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
