{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 Part 2: Customer Segmentation using Support Vector Machines (SVM)\n",
    "\n",
    "## Objective\n",
    "Develop a machine learning model using SVM techniques to classify customers as \"High value\" or \"Low value\" based on features like Age, Income, Spending Score, and Region.\n",
    "\n",
    "## Learning Outcomes\n",
    "- Explain the concepts and mathematics behind SVMs and their applications\n",
    "- Describe the structure and function of neural networks, including their learning processes\n",
    "- Identify and evaluate the fundamental concepts of deep learning, including popular architectures and their applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../Task_1_Part_2_Assets/customersegmentation.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nFirst 10 rows of the dataset:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nStatistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nTarget Variable Distribution (Customer_Category):\")\n",
    "print(df['Customer_Category'].value_counts())\n",
    "print(f\"\\nClass 0 (Low Value): {(df['Customer_Category'] == 0).sum()} customers\")\n",
    "print(f\"Class 1 (High Value): {(df['Customer_Category'] == 1).sum()} customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Target distribution\n",
    "ax1 = axes[0]\n",
    "target_counts = df['Customer_Category'].value_counts()\n",
    "colors = ['#ff6b6b', '#4ecdc4']\n",
    "ax1.bar(['Low Value (0)', 'High Value (1)'], target_counts.values, color=colors, edgecolor='black')\n",
    "ax1.set_title('Customer Category Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Count')\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    ax1.text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Region distribution\n",
    "ax2 = axes[1]\n",
    "region_counts = df['Region'].value_counts()\n",
    "ax2.bar(region_counts.index, region_counts.values, color='steelblue', edgecolor='black')\n",
    "ax2.set_title('Region Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Count')\n",
    "for i, v in enumerate(region_counts.values):\n",
    "    ax2.text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical feature distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "numerical_features = ['Age', 'Income', 'Spending_Score']\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    ax = axes[i]\n",
    "    for category in [0, 1]:\n",
    "        subset = df[df['Customer_Category'] == category][feature]\n",
    "        label = 'Low Value' if category == 0 else 'High Value'\n",
    "        ax.hist(subset, alpha=0.6, label=label, bins=20, edgecolor='black')\n",
    "    ax.set_title(f'{feature} Distribution by Customer Category', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "# First, encode Region for correlation\n",
    "df_encoded = df.copy()\n",
    "le = LabelEncoder()\n",
    "df_encoded['Region_Encoded'] = le.fit_transform(df['Region'])\n",
    "\n",
    "# Create correlation matrix\n",
    "correlation_features = ['Age', 'Income', 'Spending_Score', 'Region_Encoded', 'Customer_Category']\n",
    "corr_matrix = df_encoded[correlation_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
    "            linewidths=0.5, fmt='.3f', square=True)\n",
    "plt.title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation with Target (Customer_Category):\")\n",
    "print(corr_matrix['Customer_Category'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnamed index column if present\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Encode categorical variable (Region)\n",
    "print(\"Unique Regions:\", df['Region'].unique())\n",
    "\n",
    "# One-hot encoding for Region\n",
    "df_processed = pd.get_dummies(df, columns=['Region'], drop_first=False)\n",
    "\n",
    "print(\"\\nProcessed DataFrame columns:\")\n",
    "print(df_processed.columns.tolist())\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_processed.drop('Customer_Category', axis=1)\n",
    "y = df_processed['Customer_Category']\n",
    "\n",
    "print(f\"Feature Matrix Shape: {X.shape}\")\n",
    "print(f\"Target Vector Shape: {y.shape}\")\n",
    "print(f\"\\nFeatures: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Verify stratification\n",
    "print(f\"\\nTraining set class distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Testing set class distribution: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling - Important for SVM!\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for better visualization\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "print(\"Feature Scaling Applied!\")\n",
    "print(\"\\nScaled Training Data Statistics:\")\n",
    "print(X_train_scaled_df.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Building SVM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Linear SVM model\n",
    "svm_linear = SVC(kernel='linear', random_state=42)\n",
    "svm_linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_linear = svm_linear.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=\" * 60)\n",
    "print(\"LINEAR SVM RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_linear):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_linear):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_linear):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_linear):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_linear, target_names=['Low Value', 'High Value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 RBF (Radial Basis Function) Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RBF SVM model\n",
    "svm_rbf = SVC(kernel='rbf', random_state=42)\n",
    "svm_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rbf = svm_rbf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=\" * 60)\n",
    "print(\"RBF KERNEL SVM RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rbf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_rbf):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_rbf):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_rbf):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rbf, target_names=['Low Value', 'High Value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Polynomial Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Polynomial SVM model\n",
    "svm_poly = SVC(kernel='poly', degree=3, random_state=42)\n",
    "svm_poly.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_poly = svm_poly.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=\" * 60)\n",
    "print(\"POLYNOMIAL KERNEL SVM RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_poly):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_poly):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_poly):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_poly):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_poly, target_names=['Low Value', 'High Value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "models = {\n",
    "    'Linear SVM': svm_linear,\n",
    "    'RBF SVM': svm_rbf,\n",
    "    'Polynomial SVM': svm_poly\n",
    "}\n",
    "\n",
    "predictions = {\n",
    "    'Linear SVM': y_pred_linear,\n",
    "    'RBF SVM': y_pred_rbf,\n",
    "    'Polynomial SVM': y_pred_poly\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = []\n",
    "for name, y_pred in predictions.items():\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart comparison\n",
    "ax1 = axes[0]\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "for i, (name, row) in enumerate(comparison_df.iterrows()):\n",
    "    values = [comparison_df.loc[i, m] for m in metrics]\n",
    "    ax1.bar(x + i*width, values, width, label=comparison_df.loc[i, 'Model'], color=colors[i])\n",
    "\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x + width)\n",
    "ax1.set_xticklabels(metrics)\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Confusion matrices\n",
    "ax2 = axes[1]\n",
    "best_model_name = comparison_df.loc[comparison_df['Accuracy'].idxmax(), 'Model']\n",
    "best_y_pred = predictions[best_model_name]\n",
    "cm = confusion_matrix(y_test, best_y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Low Value', 'High Value'])\n",
    "disp.plot(ax=ax2, cmap='Blues')\n",
    "ax2.set_title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for optimal hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OPTIMIZED SVM RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_best):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Low Value', 'High Value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Analysis of Support Vectors and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Support Vectors (using Linear SVM for interpretability)\n",
    "print(\"=\" * 60)\n",
    "print(\"SUPPORT VECTOR ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nNumber of Support Vectors: {len(svm_linear.support_)}\")\n",
    "print(f\"Support Vectors per class: {svm_linear.n_support_}\")\n",
    "print(f\"\\nTotal training samples: {len(X_train)}\")\n",
    "print(f\"Percentage of support vectors: {len(svm_linear.support_) / len(X_train) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis (for Linear SVM)\n",
    "# In linear SVM, the weight vector (coef_) indicates feature importance\n",
    "\n",
    "feature_weights = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Weight': svm_linear.coef_[0],\n",
    "    'Absolute_Weight': np.abs(svm_linear.coef_[0])\n",
    "}).sort_values('Absolute_Weight', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE IMPORTANCE (Linear SVM)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nFeature weights (sorted by absolute importance):\")\n",
    "print(feature_weights.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Bar chart of feature weights\n",
    "ax1 = axes[0]\n",
    "colors = ['#e74c3c' if w < 0 else '#2ecc71' for w in feature_weights['Weight']]\n",
    "bars = ax1.barh(feature_weights['Feature'], feature_weights['Weight'], color=colors, edgecolor='black')\n",
    "ax1.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax1.set_xlabel('Weight Coefficient')\n",
    "ax1.set_title('Feature Weights in Linear SVM\\n(Positive = Contributes to High Value, Negative = Contributes to Low Value)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Absolute importance\n",
    "ax2 = axes[1]\n",
    "ax2.barh(feature_weights['Feature'], feature_weights['Absolute_Weight'], color='steelblue', edgecolor='black')\n",
    "ax2.set_xlabel('Absolute Weight')\n",
    "ax2.set_title('Feature Importance (Absolute)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify most important feature\n",
    "most_important_feature = feature_weights.iloc[0]['Feature']\n",
    "print(f\"\\nüîë Most influential feature: {most_important_feature}\")\n",
    "print(f\"   Weight: {feature_weights.iloc[0]['Weight']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Margin Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate margin width for Linear SVM\n",
    "# Margin width = 2 / ||w|| where w is the weight vector\n",
    "\n",
    "weight_norm = np.linalg.norm(svm_linear.coef_)\n",
    "margin_width = 2 / weight_norm\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MARGIN ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nWeight Vector Norm (||w||): {weight_norm:.4f}\")\n",
    "print(f\"Margin Width (2/||w||): {margin_width:.4f}\")\n",
    "\n",
    "# Analyze margin for different C values\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"Margin Width for Different C Values:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "c_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "margin_data = []\n",
    "\n",
    "for c in c_values:\n",
    "    temp_svm = SVC(kernel='linear', C=c, random_state=42)\n",
    "    temp_svm.fit(X_train_scaled, y_train)\n",
    "    temp_norm = np.linalg.norm(temp_svm.coef_)\n",
    "    temp_margin = 2 / temp_norm\n",
    "    temp_accuracy = accuracy_score(y_test, temp_svm.predict(X_test_scaled))\n",
    "    temp_n_sv = len(temp_svm.support_)\n",
    "    \n",
    "    margin_data.append({\n",
    "        'C': c,\n",
    "        'Margin_Width': temp_margin,\n",
    "        'Num_Support_Vectors': temp_n_sv,\n",
    "        'Test_Accuracy': temp_accuracy\n",
    "    })\n",
    "    \n",
    "margin_df = pd.DataFrame(margin_data)\n",
    "print(margin_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize margin vs C relationship\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Margin Width vs C\n",
    "ax1 = axes[0]\n",
    "ax1.plot(margin_df['C'], margin_df['Margin_Width'], 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('C (Regularization Parameter)')\n",
    "ax1.set_ylabel('Margin Width')\n",
    "ax1.set_title('Margin Width vs. C', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Number of Support Vectors vs C\n",
    "ax2 = axes[1]\n",
    "ax2.plot(margin_df['C'], margin_df['Num_Support_Vectors'], 'ro-', linewidth=2, markersize=8)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('C (Regularization Parameter)')\n",
    "ax2.set_ylabel('Number of Support Vectors')\n",
    "ax2.set_title('Support Vectors vs. C', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy vs C\n",
    "ax3 = axes[2]\n",
    "ax3.plot(margin_df['C'], margin_df['Test_Accuracy'], 'go-', linewidth=2, markersize=8)\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_xlabel('C (Regularization Parameter)')\n",
    "ax3.set_ylabel('Test Accuracy')\n",
    "ax3.set_title('Test Accuracy vs. C', fontsize=12, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Model Stability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model stability by retraining with different random states\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL STABILITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stability_results = []\n",
    "support_vector_counts = []\n",
    "\n",
    "for seed in range(10):\n",
    "    # Different train/test split\n",
    "    X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale\n",
    "    scaler_temp = StandardScaler()\n",
    "    X_train_temp_scaled = scaler_temp.fit_transform(X_train_temp)\n",
    "    X_test_temp_scaled = scaler_temp.transform(X_test_temp)\n",
    "    \n",
    "    # Train model\n",
    "    svm_temp = SVC(kernel='linear', random_state=42)\n",
    "    svm_temp.fit(X_train_temp_scaled, y_train_temp)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_temp = svm_temp.predict(X_test_temp_scaled)\n",
    "    acc = accuracy_score(y_test_temp, y_pred_temp)\n",
    "    n_sv = len(svm_temp.support_)\n",
    "    \n",
    "    stability_results.append(acc)\n",
    "    support_vector_counts.append(n_sv)\n",
    "\n",
    "print(f\"\\nAccuracy across 10 different splits:\")\n",
    "print(f\"  Mean: {np.mean(stability_results):.4f}\")\n",
    "print(f\"  Std:  {np.std(stability_results):.4f}\")\n",
    "print(f\"  Min:  {np.min(stability_results):.4f}\")\n",
    "print(f\"  Max:  {np.max(stability_results):.4f}\")\n",
    "\n",
    "print(f\"\\nSupport Vector Count across 10 different splits:\")\n",
    "print(f\"  Mean: {np.mean(support_vector_counts):.1f}\")\n",
    "print(f\"  Std:  {np.std(support_vector_counts):.1f}\")\n",
    "print(f\"  Min:  {np.min(support_vector_counts)}\")\n",
    "print(f\"  Max:  {np.max(support_vector_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for stability assessment\n",
    "cv_scores = cross_val_score(SVC(kernel='linear', random_state=42), X_train_scaled, y_train, cv=10)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"10-Fold Cross-Validation Results:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Individual Fold Scores: {cv_scores.round(4)}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std CV Score: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Kernel Comparison Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance across different kernels\n",
    "print(\"=\" * 60)\n",
    "print(\"KERNEL COMPARISON ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "kernel_results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    svm_temp = SVC(kernel=kernel, random_state=42)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(svm_temp, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    # Fit and predict\n",
    "    svm_temp.fit(X_train_scaled, y_train)\n",
    "    y_pred_temp = svm_temp.predict(X_test_scaled)\n",
    "    test_acc = accuracy_score(y_test, y_pred_temp)\n",
    "    \n",
    "    kernel_results.append({\n",
    "        'Kernel': kernel,\n",
    "        'CV_Mean': cv_scores.mean(),\n",
    "        'CV_Std': cv_scores.std(),\n",
    "        'Test_Accuracy': test_acc,\n",
    "        'Num_Support_Vectors': len(svm_temp.support_)\n",
    "    })\n",
    "\n",
    "kernel_df = pd.DataFrame(kernel_results)\n",
    "print(\"\\nKernel Performance Comparison:\")\n",
    "print(kernel_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize kernel comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(kernels))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, kernel_df['CV_Mean'], width, label='CV Mean', color='steelblue', \n",
    "                yerr=kernel_df['CV_Std'], capsize=5)\n",
    "bars2 = ax1.bar(x + width/2, kernel_df['Test_Accuracy'], width, label='Test Accuracy', color='coral')\n",
    "\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Kernel Performance Comparison', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(kernel_df['Kernel'])\n",
    "ax1.legend()\n",
    "ax1.set_ylim([0.4, 0.7])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Support vectors comparison\n",
    "ax2 = axes[1]\n",
    "ax2.bar(kernel_df['Kernel'], kernel_df['Num_Support_Vectors'], color='purple', edgecolor='black')\n",
    "ax2.set_ylabel('Number of Support Vectors')\n",
    "ax2.set_title('Support Vectors by Kernel', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Answering the Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: How do support vectors impact the decision boundary in SVM? Which feature has the strongest influence on customer segmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"QUESTION 1: Support Vectors and Feature Importance\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "üìå HOW SUPPORT VECTORS IMPACT THE DECISION BOUNDARY:\n",
    "\n",
    "Support vectors are the critical data points that lie closest to the decision boundary\n",
    "(hyperplane) in SVM. They have a fundamental impact on the decision boundary in the\n",
    "following ways:\n",
    "\n",
    "1. **Definition of the Hyperplane**: The decision boundary is determined SOLELY by the\n",
    "   support vectors. All other data points have no influence on the position of the\n",
    "   hyperplane.\n",
    "\n",
    "2. **Margin Determination**: Support vectors define the margin - the distance between\n",
    "   the decision boundary and the nearest data points. The SVM algorithm maximizes this\n",
    "   margin to improve generalization.\n",
    "\n",
    "3. **Robustness**: Because only support vectors matter, the model is robust to changes\n",
    "   in non-support vector points. This is a key advantage of SVMs.\n",
    "\n",
    "4. **Computational Efficiency**: During prediction, only support vectors are used,\n",
    "   making the model efficient even with large datasets.\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nüìä In our customer segmentation model:\")\n",
    "print(f\"   - Total training samples: {len(X_train)}\")\n",
    "print(f\"   - Number of support vectors: {len(svm_linear.support_)}\")\n",
    "print(f\"   - Percentage: {len(svm_linear.support_) / len(X_train) * 100:.2f}%\")\n",
    "print(f\"   - Support vectors per class: {svm_linear.n_support_}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nüìå FEATURE WITH STRONGEST INFLUENCE:\\n\")\n",
    "print(feature_weights.to_string(index=False))\n",
    "\n",
    "print(f\"\\nüîë ANSWER: The feature with the STRONGEST influence on customer segmentation is:\")\n",
    "print(f\"   Feature: {feature_weights.iloc[0]['Feature']}\")\n",
    "print(f\"   Weight: {feature_weights.iloc[0]['Weight']:.4f}\")\n",
    "print(f\"   Absolute Importance: {feature_weights.iloc[0]['Absolute_Weight']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Implications of Margin Width, Non-linear Kernels, and Support Vector Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"QUESTION 2: Margin Width, Non-linear Kernels, and Model Stability\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "üìå IF THE MARGIN WIDTH IS LARGE, WHAT DOES IT IMPLY ABOUT CLASSIFICATION CONFIDENCE?\n",
    "\n",
    "A LARGE MARGIN implies:\n",
    "\n",
    "1. **Higher Classification Confidence**: When the margin is wide, data points have a\n",
    "   larger \"buffer zone\" between classes. Points that fall well within their respective\n",
    "   sides can be classified with higher confidence.\n",
    "\n",
    "2. **Better Generalization**: A wider margin typically indicates the model will perform\n",
    "   well on unseen data, as it's not overfitting to the training examples.\n",
    "\n",
    "3. **Robustness to Noise**: The model can tolerate small perturbations in the input data\n",
    "   without changing its predictions.\n",
    "\n",
    "4. **Lower Variance**: The model is less sensitive to the specific training examples used.\n",
    "\n",
    "TRADE-OFF: Very large margins (low C) might lead to underfitting, while very small\n",
    "margins (high C) might lead to overfitting.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüìä Evidence from our analysis:\")\n",
    "print(margin_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "üìå IF THE DATA REQUIRES A NON-LINEAR KERNEL, WHAT MIGHT THAT SUGGEST ABOUT THE DATASET?\n",
    "\n",
    "The need for a non-linear kernel suggests:\n",
    "\n",
    "1. **Non-Linear Decision Boundary**: The classes cannot be separated by a straight line\n",
    "   (hyperplane) in the original feature space. The relationship between features and\n",
    "   the target is complex.\n",
    "\n",
    "2. **Complex Feature Interactions**: There may be important interactions between features\n",
    "   that a linear model cannot capture.\n",
    "\n",
    "3. **Higher-Dimensional Separability**: The kernel trick maps data to a higher-dimensional\n",
    "   space where linear separation becomes possible.\n",
    "\n",
    "4. **Data Distribution**: The data might have clusters, spirals, or other non-linear\n",
    "   patterns that require curved decision boundaries.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüìä Evidence from our kernel comparison:\")\n",
    "print(kernel_df.to_string(index=False))\n",
    "\n",
    "linear_acc = kernel_df[kernel_df['Kernel'] == 'linear']['Test_Accuracy'].values[0]\n",
    "rbf_acc = kernel_df[kernel_df['Kernel'] == 'rbf']['Test_Accuracy'].values[0]\n",
    "\n",
    "if rbf_acc > linear_acc:\n",
    "    print(f\"\\nüîç In our dataset: RBF kernel ({rbf_acc:.4f}) outperforms Linear ({linear_acc:.4f}),\")\n",
    "    print(\"   suggesting the data has some non-linear patterns.\")\n",
    "else:\n",
    "    print(f\"\\nüîç In our dataset: Linear kernel ({linear_acc:.4f}) performs comparably to RBF ({rbf_acc:.4f}),\")\n",
    "    print(\"   suggesting the data is relatively linearly separable.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "üìå IF SUPPORT VECTORS CHANGE SIGNIFICANTLY WHEN RETRAINED, WHAT DOES THAT IMPLY ABOUT\n",
    "   MODEL STABILITY?\n",
    "\n",
    "Significant changes in support vectors indicate:\n",
    "\n",
    "1. **Low Model Stability**: The model is sensitive to the specific training examples,\n",
    "   which can lead to inconsistent predictions on new data.\n",
    "\n",
    "2. **Overlapping Classes**: The data may have significant overlap between classes,\n",
    "   making the boundary definition ambiguous.\n",
    "\n",
    "3. **Insufficient or Noisy Data**: There might not be enough data, or the data may\n",
    "   contain noise that affects which points become support vectors.\n",
    "\n",
    "4. **High Variance**: Small changes in the training data lead to different models,\n",
    "   indicating high variance.\n",
    "\n",
    "5. **Need for Regularization**: The C parameter might need adjustment - a smaller C\n",
    "   allows more flexibility and might lead to more stable support vectors.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüìä Evidence from our stability analysis:\")\n",
    "print(f\"   Support Vector Count across splits:\")\n",
    "print(f\"   - Mean: {np.mean(support_vector_counts):.1f}\")\n",
    "print(f\"   - Std:  {np.std(support_vector_counts):.1f}\")\n",
    "print(f\"   - Range: {np.min(support_vector_counts)} to {np.max(support_vector_counts)}\")\n",
    "print(f\"\\n   Accuracy across splits:\")\n",
    "print(f\"   - Mean: {np.mean(stability_results):.4f}\")\n",
    "print(f\"   - Std:  {np.std(stability_results):.4f}\")\n",
    "\n",
    "sv_variation = np.std(support_vector_counts) / np.mean(support_vector_counts) * 100\n",
    "if sv_variation > 10:\n",
    "    stability_assessment = \"potentially unstable (high variation in support vectors)\"\n",
    "else:\n",
    "    stability_assessment = \"relatively stable (low variation in support vectors)\"\n",
    "\n",
    "print(f\"\\nüîç Our model is {stability_assessment}\")\n",
    "print(f\"   Coefficient of variation for support vectors: {sv_variation:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY AND CONCLUSIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "üìã KEY FINDINGS:\n",
    "\n",
    "1. MODEL PERFORMANCE:\n",
    "\"\"\")\n",
    "print(f\"   - Best performing kernel: {comparison_df.loc[comparison_df['Accuracy'].idxmax(), 'Model']}\")\n",
    "print(f\"   - Best test accuracy: {comparison_df['Accuracy'].max():.4f}\")\n",
    "print(f\"   - After hyperparameter tuning: {accuracy_score(y_test, y_pred_best):.4f}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "2. FEATURE IMPORTANCE:\n",
    "   - Most influential feature: {feature_weights.iloc[0]['Feature']}\n",
    "   - The numerical features (Age, Income, Spending_Score) generally show\n",
    "     stronger influence than the regional categorical variables.\n",
    "\n",
    "3. SUPPORT VECTOR ANALYSIS:\n",
    "   - Number of support vectors: {len(svm_linear.support_)} out of {len(X_train)} training samples\n",
    "   - This represents {len(svm_linear.support_) / len(X_train) * 100:.2f}% of the training data\n",
    "   - A moderate percentage indicates good margin definition\n",
    "\n",
    "4. MODEL STABILITY:\n",
    "   - Cross-validation mean accuracy: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\n",
    "   - The model shows {'good' if cv_scores.std() < 0.05 else 'moderate'} stability\n",
    "\n",
    "5. DATA CHARACTERISTICS:\n",
    "   - The similar performance of linear and non-linear kernels suggests\n",
    "     the data is relatively linearly separable\n",
    "   - The margin analysis shows typical trade-off between margin width\n",
    "     and number of support vectors\n",
    "\n",
    "üìå RECOMMENDATIONS:\n",
    "   - The optimized model with parameters {grid_search.best_params_} provides\n",
    "     the best balance of accuracy and generalization\n",
    "   - Consider feature engineering to improve prediction accuracy\n",
    "   - The model can be deployed for customer segmentation with reasonable confidence\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL MODEL CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nBest Model Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Test Set Performance:\")\n",
    "print(f\"  - Accuracy:  {accuracy_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"  - Precision: {precision_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"  - Recall:    {recall_score(y_test, y_pred_best):.4f}\")\n",
    "print(f\"  - F1-Score:  {f1_score(y_test, y_pred_best):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
